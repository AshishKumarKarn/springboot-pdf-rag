# ğŸ“„ PDF RAG API using Spring Boot & Local LLM (Ollama Mistral)

This project provides a full-stack solution to perform **question-answering on PDF documents** using **local Large Language Models (LLMs)**. It combines the power of **Python for text processing and embeddings** with **Spring Boot** for RESTful API exposure.

No cloud API usage â€” everything runs locally using **Ollama Mistral**, **FAISS**, and **Sentence Transformers**.

---

## âœ¨ Features

- ğŸ” Extracts text from PDF using Python and PyPDF2
- ğŸ“š Embeds PDF content using Sentence Transformers (`all-MiniLM-L6-v2`)
- âš¡ Stores and searches text embeddings using FAISS
- ğŸ§  Answers questions using locally running **Mistral** via Ollama
- â˜ï¸ No external API calls â€” fully local
- ğŸš€ REST API exposed through Spring Boot at `/api/rag/ask`

---

## ğŸ§© Tech Stack

### ğŸ Python (used for document processing)

- `PyPDF2` â€“ PDF text extraction
- `SentenceTransformers` â€“ Text embeddings
- `FAISS` â€“ Vector store and retrieval
- `NumPy` â€“ Embedding manipulation
- `venv` â€“ Pre-installed virtual environment

### â˜• Spring Boot (used to expose REST API)

- Java 24
- REST Controller (`/api/rag/ask`)
- Communicates with Python script

### ğŸ§  Local LLM

- **Ollama** â€“ Lightweight local LLM runtime
- **Mistral** â€“ Local model pulled via Ollama CLI

---

## ğŸ“ Project Structure

```text
project-root/
â”œâ”€â”€ springboot-app/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ main/java/...                # Spring Boot code
â”‚   â””â”€â”€ resources/
â”‚       â””â”€â”€ application.properties       # Configurations
â”‚       â””â”€â”€ venv/                        # Python virtual environment (preinstalled)
â”‚       â””â”€â”€ embed_pdf_search.py          # Script to read and embed PDF
â”‚       â””â”€â”€ resume.pdf                   # PDF file to be processed
â””â”€â”€ README.md

```
## ğŸš€ Getting Started

### Prerequisites
- Java 24
- Maven
- Python 3.8
- Ollama installed (https://ollama.com/docs/installation)
- Ollama Mistral model pulled (run `ollama pull mistral`)

---
#### Note: May take a few minutes to run the first time depending on the hardware.
curl
```
curl --location 'http://localhost:8081/api/rag/ask?question=do%20you%20have%20the%20contact%20of%20Ashish%20Kumar%20Karn%3F'
```
